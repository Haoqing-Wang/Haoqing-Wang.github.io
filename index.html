<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Haoqing Wang</title>
  
  <meta name="author" content="Haoqing Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Haoqing Wang</name>
              </p>
              <p> I am now a PhD candidate (expected to graduate in June 2024) at <a href="https://www.cis.pku.edu.cn/">School of Intelligence Science and Technology</a>, <a href="https://www.pku.edu.cn/">Peking University</a>. I am a member of National Key Lab of General AI, and advised by Professor <a href="https://scholar.google.com.hk/citations?user=tRoAxlsAAAAJ&hl=zh-CN">Zhi-Hong Deng</a>. Previously, I received my Bachelor of Science in mathematics from <a href="https://www.buaa.edu.cn/">Beihang University</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:wanghaoqing@pku.edu.cn">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com.hk/citations?user=A2kCYnUAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Haoqing-Wang">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:40%;max-width:40%" alt="profile photo" src="images/HaoqingW_2.jpg" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in self-supervised learning, diffusion models and meta-learning. Concretely, I focus on representation learning (large model pre-training) and generation models (e.g., diffusion models) in computer vision.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="works/LocalMIM.png" alt="blind-date" width="120" height="120"></td>
            <td width="75%" valign="middle">
              <papertitle>Masked Image Modeling with Local Multi-Scale Reconstruction</papertitle>
              <br>
              <strong>Haoqing Wang</strong>, <a href="https://scholar.google.com.hk/citations?user=TkSZQ6gAAAAJ&hl=zh-CN&oi=ao">Yehui Tang</a>, <a href="https://www.wangyunhe.site/">Yunhe Wang</a>, <a href="https://scholar.google.com.hk/citations?user=UnAbd4gAAAAJ&hl=zh-CN&oi=ao">Jianyuan Guo</a>, <a href="https://scholar.google.com.hk/citations?user=tRoAxlsAAAAJ&hl=zh-CN">Zhi-Hong Deng</a>, <a href="https://scholar.google.com.hk/citations?user=vThoBVcAAAAJ&hl=zh-CN&oi=ao">Kai Han</a>
              <br>
              <em>CVPR</em>, 2023 <font color="red"><strong>(<a href="works/email.pdf">Highlight/Oral</a> Presentation, Top 2.5%)</strong></font>. CCF-A.
              <p> <a href="https://arxiv.org/pdf/2303.05251v1.pdf">paper</a> / <a href="https://github.com/Haoqing-Wang/LocalMIM">code</a> / <a href="https://zhuanlan.zhihu.com/p/613629304">blog</a> </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="works/ATA.png" alt="blind-date" width="120" height="120"></td>
            <td width="75%" valign="middle">
              <papertitle>Towards well-generalizing meta-learning via adversarial task augmentation</papertitle>
              <br>
              <strong>Haoqing Wang</strong>, Huiyu Mai, Yuhang Gong, <a href="https://scholar.google.com.hk/citations?user=tRoAxlsAAAAJ&hl=zh-CN">Zhi-Hong Deng</a>
              <br>
              <em>Artificial Intelligence</em>, 103875, 2023. CCF-A, IF=14.05.
              <p> <a href="https://www.sciencedirect.com/science/article/pii/S0004370223000218">paper</a> / <a href="https://github.com/Haoqing-Wang/CDFSL-ATA">code</a> </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="works/CPNWCP.png" alt="blind-date" width="120" height="130"></td>
            <td width="75%" valign="middle">
              <papertitle>Contrastive Prototypical Network with Wasserstein Confidence Penalty</papertitle>
              <br>
              <strong>Haoqing Wang</strong>, <a href="https://scholar.google.com.hk/citations?user=tRoAxlsAAAAJ&hl=zh-CN">Zhi-Hong Deng</a>
              <br>
              <em>ECCV</em>, 2022. CCF-B.
              <p> <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136790654.pdf">paper</a> / <a href="https://github.com/Haoqing-Wang/CPNWCP">code</a> </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="works/InfoCL.png" alt="blind-date" width="120" height="100"></td>
            <td width="75%" valign="middle">
              <papertitle>Rethinking minimal sufficient representation in contrastive learning</papertitle>
              <br>
              <strong>Haoqing Wang</strong>, <a href="https://www.microsoft.com/en-us/research/people/xunguo/">Xun Guo</a>, <a href="https://scholar.google.com.hk/citations?user=tRoAxlsAAAAJ&hl=zh-CN">Zhi-Hong Deng</a>, <a href="https://www.microsoft.com/en-us/research/people/yanlu/" >Yan Lu</a>
              <br>
              <em>CVPR</em>, 2022 <font color="red"><strong>(<a href="https://cvpr2022.thecvf.com/orals-624-am">Oral</a> Presentation, Top 4.2%)</strong></font>. CCF-A.
              <br>
              <p> <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Rethinking_Minimal_Sufficient_Representation_in_Contrastive_Learning_CVPR_2022_paper.pdf">paper</a> / <a href="https://github.com/Haoqing-Wang/InfoCL">code</a> </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="works/ATA_IJCAI.png" alt="blind-date" width="120" height="120"></td>
            <td width="75%" valign="middle">
              <papertitle>Cross-domain few-shot classification via adversarial task augmentation</papertitle>
              <br>
              <strong>Haoqing Wang</strong>, <a href="https://scholar.google.com.hk/citations?user=tRoAxlsAAAAJ&hl=zh-CN">Zhi-Hong Deng</a>
              <br>
              <em>IJCAI</em>, 2021. CCF-A.
              <p> <a href="https://www.ijcai.org/proceedings/2021/0149.pdf">paper</a> / <a href="https://github.com/Haoqing-Wang/CDFSL-ATA">code</a> / <a href="https://zhuanlan.zhihu.com/p/370583079">blog</a> </p>
            </td>
          </tr>
		
	  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="works/Di2Vec.png" alt="blind-date" width="120" height="120"></td>
            <td width="75%" valign="middle">
              <papertitle>Distributed representations of diseases based on co-occurrence relationship</papertitle>
              <br>
              <strong>Haoqing Wang</strong>, Huiyu Mai, <a href="https://scholar.google.com.hk/citations?user=tRoAxlsAAAAJ&hl=zh-CN">Zhi-Hong Deng</a>, Chao Yang, <a href="https://www.researchgate.net/profile/Luxia-Zhang-3">Luxia Zhang</a>, Huai-yu Wang,
              <br>
              <em>Expert Systems with Applications</em> 183, 115418, 2021. CCF-C, IF=8.665.
              <p> <a href="https://www.sciencedirect.com/science/article/pii/S095741742100837X">paper</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="works/FSLSTM.png" alt="blind-date" width="120" height="100"></td>
            <td width="75%" valign="middle">
              <papertitle>Few-shot learning with LSSVM base learner and transductive modules</papertitle>
              <br>
              <strong>Haoqing Wang</strong>, <a href="https://scholar.google.com.hk/citations?user=tRoAxlsAAAAJ&hl=zh-CN">Zhi-Hong Deng</a>
              <br>
              arXiv preprint arXiv:2009.05786
              <p> <a href="https://arxiv.org/pdf/2009.05786.pdf">paper</a> / <a href="https://github.com/Haoqing-Wang/FSLSTM">code</a> </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="works/NART.png" alt="blind-date" width="120" height="120"></td>
            <td width="75%" valign="middle">
              <papertitle>Fast structured decoding for sequence models</papertitle>
              <br>
              <a href="http://www.cs.cmu.edu/~zhiqings/">Zhiqing Sun</a>, <a href="https://people.eecs.berkeley.edu/~zhuohan/">Zhuohan Li</a>, <strong>Haoqing Wang</strong>, <a href="https://zi-lin.com/">Zi Lin</a>, <a href="https://dihe-pku.github.io/">Di He</a>, <a href="https://scholar.google.com.hk/citations?user=tRoAxlsAAAAJ&hl=zh-CN">Zhi-Hong Deng</a>
              <br>
              <em>NeurIPS</em>, 2019. CCF-A.
              <p> <a href="https://proceedings.neurips.cc/paper/2019/file/74563ba21a90da13dacf2a73e3ddefa7-Paper.pdf">paper</a> / <a href="https://github.com/Edward-Sun/structured-nart">code</a> </p>
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Internships</heading>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/ark.png" alt="clean-usnob" width="200" height="100"></td>
            <td width="75%" valign="middle">
              Algorithm Application Department
              <br>
              2022/06/15-2022/03/16, advised by <a href="https://scholar.google.com.hk/citations?user=vThoBVcAAAAJ&hl=zh-CN&oi=ao">Kai Han</a>
              <br>
              During the internship, I conduct deep research on masked image modeling and propose a new pretext task, local multi-scale reconstruction, to accelerate representation learning. This work has been accepted by CVPR 2023 as Highlight/Oral presentation (Top 2.5%).
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/msra.png" alt="clean-usnob" width="200" height="100"></td>
            <td width="75%" valign="center">
              <a href="https://www.microsoft.com/en-us/research/group/multimedia-search-and-mining/">Multimedia Search and Mining Group</a>
              <br>
              2021/07/20-2022/04/11, advised by <a href="https://www.microsoft.com/en-us/research/people/xunguo/">Xun Guo</a>
              <br>
              During the internship, I conduct deep research on contrastive learning, revealing its shortcomings from a theoretical perspective and proposing solutions. This work has been accepted by CVPR 2022 as Oral presentation (Top 4.2%).
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Professional Services</heading>
              <p>
              Reviewer for CVPR, ICCV, NeurIPS, ICLR, ECCV, IJCV, TMM, ...
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
